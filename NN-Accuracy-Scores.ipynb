{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:25.070791Z",
     "iopub.status.busy": "2020-10-06T02:42:25.069843Z",
     "iopub.status.idle": "2020-10-06T02:42:32.676571Z",
     "shell.execute_reply": "2020-10-06T02:42:32.675868Z"
    },
    "papermill": {
     "duration": 7.637684,
     "end_time": "2020-10-06T02:42:32.676719",
     "exception": false,
     "start_time": "2020-10-06T02:42:25.039035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "########################################################################\n",
    "# Python Standard Libraries\n",
    "import os\n",
    "import multiprocessing\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "import math\n",
    "\n",
    "########################################################################\n",
    "# Numpy Library\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "########################################################################\n",
    "# Pandas Library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "########################################################################\n",
    "# MATPLOT Library\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "########################################################################\n",
    "# SKLearn Library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, classification_report, confusion_matrix, average_precision_score, roc_curve, auc, multilabel_confusion_matrix\n",
    "\n",
    "########################################################################\n",
    "# SCIPY Library\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Keras Library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "########################################################################\n",
    "# Init random seed\n",
    "#seed = 13\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:32.741688Z",
     "iopub.status.busy": "2020-10-06T02:42:32.705416Z",
     "iopub.status.idle": "2020-10-06T02:42:33.522810Z",
     "shell.execute_reply": "2020-10-06T02:42:33.523582Z"
    },
    "papermill": {
     "duration": 0.836905,
     "end_time": "2020-10-06T02:42:33.523767",
     "exception": false,
     "start_time": "2020-10-06T02:42:32.686862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM:                   18.621841 GB\n",
      "CORES:                 4\n",
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              4\r\n",
      "On-line CPU(s) list: 0-3\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  2\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               79\r\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
      "Stepping:            0\r\n",
      "CPU MHz:             2200.000\r\n",
      "BogoMIPS:            4400.00\r\n",
      "Hypervisor vendor:   KVM\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            56320K\r\n",
      "NUMA node0 CPU(s):   0-3\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "########################################################################\n",
    "# Print system information\n",
    "def print_system_info():\n",
    "    mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "    mem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\n",
    "    print(\"{:<23}{:f} GB\".format('RAM:', mem_gib))\n",
    "    print(\"{:<23}{:d}\".format('CORES:', multiprocessing.cpu_count()))\n",
    "    !lscpu\n",
    "\n",
    "########################################################################\n",
    "# Walk through input files\n",
    "def print_input_files():\n",
    "    # Input data files are available in the \"../input/\" directory.\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "########################################################################\n",
    "# Dump text files\n",
    "def dump_text_file(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "########################################################################\n",
    "# Dump CSV files\n",
    "def dump_csv_file(fname, count=5):\n",
    "    # count: 0 - column names only, -1 - all rows, default = 5 rows max\n",
    "    df = pd.read_csv(fname)\n",
    "    if count < 0:\n",
    "        count = df.shape[0]\n",
    "    return df.head(count)\n",
    "\n",
    "########################################################################\n",
    "# Dataset related functions\n",
    "ds_nbaiot = '/kaggle/input/nbaiot-dataset'\n",
    "dn_nbaiot = ['Danmini_Doorbell', 'Ecobee_Thermostat', 'Ennio_Doorbell', 'Philips_B120N10_Baby_Monitor', 'Provision_PT_737E_Security_Camera', 'Provision_PT_838_Security_Camera', 'Samsung_SNH_1011_N_Webcam', 'SimpleHome_XCS7_1002_WHT_Security_Camera', 'SimpleHome_XCS7_1003_WHT_Security_Camera']\n",
    "\n",
    "def fname(ds, f):\n",
    "    if '.csv' not in f:\n",
    "        f = f'{f}.csv'\n",
    "    return os.path.join(ds, f)\n",
    "\n",
    "def fname_nbaiot(f):\n",
    "    return fname(ds_nbaiot, f)\n",
    "\n",
    "def get_nbaiot_device_files():\n",
    "    nbaiot_all_files = dump_csv_file(fname_nbaiot('data_summary'), -1)\n",
    "    nbaiot_all_files = nbaiot_all_files.iloc[:,0:1].values\n",
    "    device_id = 1\n",
    "    indices = []\n",
    "    for j in range(len(nbaiot_all_files)):\n",
    "        if str(device_id) not in str(nbaiot_all_files[j]):\n",
    "            indices.append(j)\n",
    "            device_id += 1\n",
    "    nbaiot_device_files = np.split(nbaiot_all_files, indices)\n",
    "    return nbaiot_device_files\n",
    "\n",
    "def get_nbaiot_device_data(device_id, count_norm=-1, count_anom=-1):\n",
    "    if device_id < 1 or device_id > 9:\n",
    "        assert False, \"Please provide a valid device ID 1-9, both inclusive\"\n",
    "    if count_anom == -1:\n",
    "        count_anom = count_norm\n",
    "    device_index = device_id -1\n",
    "    device_files = get_nbaiot_device_files()\n",
    "    device_file = device_files[device_index]\n",
    "    df = pd.DataFrame()\n",
    "    y = []\n",
    "    for i in range(len(device_file)):\n",
    "        fname = str(device_file[i][0])\n",
    "        df_c = pd.read_csv(fname_nbaiot(fname))\n",
    "        count = count_anom\n",
    "        if 'benign' in fname:\n",
    "            count = count_norm\n",
    "        rows = count if count >=0 else df_c.shape[0]\n",
    "        print(\"processing\", fname, \"rows =\", rows)\n",
    "        y_np = np.ones(rows) if 'benign' in fname else np.zeros(rows)\n",
    "        y.extend(y_np.tolist())\n",
    "        df = pd.concat([df.iloc[:,:].reset_index(drop=True),\n",
    "                      df_c.iloc[:rows,:].reset_index(drop=True)], axis=0)\n",
    "    X = df.iloc[:,:].values\n",
    "    y = np.array(y)\n",
    "    Xdf = df\n",
    "    return (X, y, Xdf)\n",
    "\n",
    "def get_nbaiot_devices_data():\n",
    "    devices_data = []\n",
    "    for i in range(9):\n",
    "        device_id = i + 1\n",
    "        (X, y) = get_nbaiot_device_data(device_id)\n",
    "        devices_data.append((X, y))\n",
    "    return devices_data\n",
    "#print_input_files()\n",
    "print_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.565823Z",
     "iopub.status.busy": "2020-10-06T02:42:33.564690Z",
     "iopub.status.idle": "2020-10-06T02:42:33.568539Z",
     "shell.execute_reply": "2020-10-06T02:42:33.567918Z"
    },
    "papermill": {
     "duration": 0.03371,
     "end_time": "2020-10-06T02:42:33.568670",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.534960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold):\n",
    "    df = df.copy()\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find features with correlation greater than a threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    # Drop features \n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "    return df.iloc[:,:].values\n",
    "\n",
    "def mark_important_features(vector, pc_keep): # pc_keep is the percentage (0-100) of labels to keep\n",
    "    th = np.percentile(vector,(100-pc_keep)) # threshold, calculate percentile (100 - percentage) from percentage\n",
    "    important_bool = (vector >= th)\n",
    "    important_int = important_bool.astype(int)\n",
    "    return important_int\n",
    "\n",
    "def select_features(X, X_norm, X_anom, threshold):\n",
    "    rows_n = X_norm.shape[0]\n",
    "    rows_a = X_anom.shape[0]\n",
    "    if rows_n == 0 or rows_a == 0:\n",
    "        return X\n",
    "\n",
    "    y_norm = np.ones(rows_n)\n",
    "    y_anom = -1 * np.ones(rows_a)\n",
    "\n",
    "    reg_n = LinearRegression(fit_intercept=False)\n",
    "    reg_n.fit(X_norm, y_norm)\n",
    "    coef_n = abs(reg_n.coef_)\n",
    "    n = mark_important_features(coef_n, threshold)\n",
    "\n",
    "    reg_a = LinearRegression(fit_intercept=False)\n",
    "    reg_a.fit(X_anom, y_anom)\n",
    "    coef_a = abs(reg_a.coef_)\n",
    "    a = mark_important_features(coef_a, threshold)\n",
    "   \n",
    "    mask = np.bitwise_or(n,a)\n",
    "    mask = mask == 1 # convert to Boolean\n",
    "    X_sel = X[:, mask]\n",
    "    return X_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.610032Z",
     "iopub.status.busy": "2020-10-06T02:42:33.599540Z",
     "iopub.status.idle": "2020-10-06T02:42:33.622051Z",
     "shell.execute_reply": "2020-10-06T02:42:33.621421Z"
    },
    "papermill": {
     "duration": 0.042499,
     "end_time": "2020-10-06T02:42:33.622182",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.579683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_changes(x, y):\n",
    "    assert x.ndim == 1 and y.ndim == 1, 'Expecting 1 dimension array, received x: {} and y: {}'.format(x.ndim, y.ndim)\n",
    "    x = x.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    xy = np.column_stack((x,y))\n",
    "    xy = xy[np.argsort(xy[:, 0])] # sort by x\n",
    "    changes = 0\n",
    "    prev_y = None\n",
    "    for i in range(1, xy.shape[0]):\n",
    "        y = xy[i][1]\n",
    "        if y != prev_y:\n",
    "            prev_y = y\n",
    "            changes += 1\n",
    "    return changes\n",
    "\n",
    "def create_network_structure_dahlia(X, y):\n",
    "    changes = []\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i]\n",
    "        change = compute_changes(x,y)\n",
    "        changes.append(change)\n",
    "    structure = list(set(changes))\n",
    "    structure = list(set(np.ceil(np.log(structure))))\n",
    "    N = X.shape[0]\n",
    "    structure = [np.floor(math.sqrt(N/2)/s) for s in structure]\n",
    "    #random.shuffle(structure)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_heuristics(X, y):\n",
    "    structure = []\n",
    "    N = X.shape[0]\n",
    "    m = 1\n",
    "    node_count_layer_1 = int(math.sqrt((m + 2) * N) + 2 * math.sqrt(N / (m + 2)))\n",
    "    node_count_layer_2 = int(m * math.sqrt(N / (m + 2)))\n",
    "    structure.append(node_count_layer_1)\n",
    "    structure.append(node_count_layer_2)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_genetic(X, y):\n",
    "    structure = []\n",
    "    l = 18\n",
    "    K = 11\n",
    "    chromosome = ''\n",
    "    for i in range(l):\n",
    "        x = random.randint(0, 1)\n",
    "        chromosome += '{}'.format(x)\n",
    "    chromosome_left = chromosome[0:K]\n",
    "    chromosome_right = chromosome[K:]\n",
    "    #print('chromosome: {}'.format(chromosome))\n",
    "    #print('split: {} {}'.format(chromosome_left, chromosome_right))\n",
    "    #print('chromosome_left: {}'.format(chromosome_left))\n",
    "    #print('chromosome_right: {}'.format(chromosome_right))\n",
    "    node_count_layer_1 = int(chromosome_left, 2) + random.randint(1, 10)\n",
    "    node_count_layer_2 = int(chromosome_right, 2) + random.randint(1, 10)\n",
    "    structure.append(node_count_layer_1)\n",
    "    structure.append(node_count_layer_2)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_random(X, y):\n",
    "    layer_count_min = 15\n",
    "    layer_count_max = 25\n",
    "    node_count_min = 10\n",
    "    node_count_max = 97\n",
    "    \n",
    "    structure = []\n",
    "    layer_count = random.randint(layer_count_min, layer_count_max)\n",
    "    for i in range(layer_count):\n",
    "        node_count = random.randint(node_count_min, node_count_max)\n",
    "        structure.append(node_count)\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.655891Z",
     "iopub.status.busy": "2020-10-06T02:42:33.654787Z",
     "iopub.status.idle": "2020-10-06T02:42:33.658376Z",
     "shell.execute_reply": "2020-10-06T02:42:33.657713Z"
    },
    "papermill": {
     "duration": 0.025201,
     "end_time": "2020-10-06T02:42:33.658505",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.633304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_binary_classifier(hidden_layers, input_dim):\n",
    "    layers = []\n",
    "    for hl in hidden_layers:\n",
    "        if hl > 0:\n",
    "            layers.append(hl)\n",
    "\n",
    "    layer_count = len(layers)\n",
    "    assert layer_count >= 1, 'at least 1 non-zero hidden layer is needed'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0],input_dim=input_dim,activation='relu'))\n",
    "    for i in range(1, layer_count):\n",
    "        model.add(Dense(layers[i],activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #model.summary()\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer ='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.689060Z",
     "iopub.status.busy": "2020-10-06T02:42:33.688079Z",
     "iopub.status.idle": "2020-10-06T02:42:33.692939Z",
     "shell.execute_reply": "2020-10-06T02:42:33.692256Z"
    },
    "papermill": {
     "duration": 0.023285,
     "end_time": "2020-10-06T02:42:33.693066",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.669781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_time_complexity_single_pass(neurons_input, structure, neurons_output):\n",
    "    count_hidden_layers = len(structure)\n",
    "    neurons = [neurons_input, *structure, neurons_output]\n",
    "    complexity = 0\n",
    "    for i in range(count_hidden_layers + 1):\n",
    "        complexity += neurons[i] * neurons[i+1]\n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.733544Z",
     "iopub.status.busy": "2020-10-06T02:42:33.732664Z",
     "iopub.status.idle": "2020-10-06T02:42:33.736282Z",
     "shell.execute_reply": "2020-10-06T02:42:33.735549Z"
    },
    "papermill": {
     "duration": 0.031698,
     "end_time": "2020-10-06T02:42:33.736425",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.704727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_report(title, model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = (y_pred > 0.25)\n",
    "    #print(y_pred)\n",
    "    #y_pred[y_pred <= 0] = -1 # convert negative values as 0 for anomaly\n",
    "    #y_pred[y_pred > 0] = 1 # convert positive values as 1 for normal\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"title,acc,tn,fp,fn,tp\")\n",
    "    print(f'{title}-cm,{acc:.2f},{tn},{fp},{fn},{tp}')\n",
    "    #print(f'{cr}')\n",
    "    results = model.evaluate(X, y, verbose=0)\n",
    "    print(f'{title}-eval,{results}')\n",
    "\n",
    "def evaluate_different_structures(title, X, y):\n",
    "    #y[y <= 0] = -1 # map negative and 0 as anomaly (-1)\n",
    "    #y[y > 0] = 1 # map positive numbers as normal (1)\n",
    "    algorithms = [\n",
    "        {'name': 'Dahlia', 'fx': create_network_structure_dahlia},\n",
    "        #{'name': 'Heuristics', 'fx': create_network_structure_heuristics},\n",
    "        #{'name': 'Genetic', 'fx': create_network_structure_genetic},\n",
    "        #{'name': 'Random', 'fx': create_network_structure_random},\n",
    "    ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    print (f\"========{title}========\")\n",
    "    feature_count = X.shape[1]\n",
    "    print(f'Features={feature_count}')\n",
    "    for algo in algorithms:\n",
    "        print(f\"********{algo['name']}********\")\n",
    "        structure = algo['fx'](X_train,y_train)\n",
    "        print(f'NN Structure: layers={len(structure)}, neurons: {structure}')\n",
    "        print('complexity: ', compute_time_complexity_single_pass(feature_count, structure, 1))\n",
    "        model = create_binary_classifier(structure, feature_count)\n",
    "        model.fit(X_train,y_train,epochs=150,batch_size=10,verbose=0)\n",
    "        compute_report('training', model, X_train, y_train)\n",
    "        compute_report('validation', model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.765625Z",
     "iopub.status.busy": "2020-10-06T02:42:33.764605Z",
     "iopub.status.idle": "2020-10-06T02:42:33.767700Z",
     "shell.execute_reply": "2020-10-06T02:42:33.766925Z"
    },
    "papermill": {
     "duration": 0.01969,
     "end_time": "2020-10-06T02:42:33.767827",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.748137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:42:33.809377Z",
     "iopub.status.busy": "2020-10-06T02:42:33.808498Z",
     "iopub.status.idle": "2020-10-06T02:47:58.246244Z",
     "shell.execute_reply": "2020-10-06T02:47:58.247221Z"
    },
    "papermill": {
     "duration": 324.467799,
     "end_time": "2020-10-06T02:47:58.247490",
     "exception": false,
     "start_time": "2020-10-06T02:42:33.779691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1.benign.csv rows = 1000\n",
      "processing 1.gafgyt.combo.csv rows = 100\n",
      "processing 1.gafgyt.junk.csv rows = 100\n",
      "processing 1.gafgyt.scan.csv rows = 100\n",
      "processing 1.gafgyt.tcp.csv rows = 100\n",
      "processing 1.gafgyt.udp.csv rows = 100\n",
      "processing 1.mirai.ack.csv rows = 100\n",
      "processing 1.mirai.scan.csv rows = 100\n",
      "processing 1.mirai.syn.csv rows = 100\n",
      "processing 1.mirai.udp.csv rows = 100\n",
      "processing 1.mirai.udpplain.csv rows = 100\n",
      "========Danmini_Doorbell========\n",
      "Features=43\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  457.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,664,0,6,670\n",
      "training-eval,[0.01564091630280018, 0.9955223798751831]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,333,3,6,318\n",
      "validation-eval,[0.16227029263973236, 0.9848484992980957]\n",
      "processing 2.benign.csv rows = 1000\n",
      "processing 2.gafgyt.combo.csv rows = 100\n",
      "processing 2.gafgyt.junk.csv rows = 100\n",
      "processing 2.gafgyt.scan.csv rows = 100\n",
      "processing 2.gafgyt.tcp.csv rows = 100\n",
      "processing 2.gafgyt.udp.csv rows = 100\n",
      "processing 2.mirai.ack.csv rows = 100\n",
      "processing 2.mirai.scan.csv rows = 100\n",
      "processing 2.mirai.syn.csv rows = 100\n",
      "processing 2.mirai.udp.csv rows = 100\n",
      "processing 2.mirai.udpplain.csv rows = 100\n",
      "========Ecobee_Thermostat========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  537.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,675,0,6,659\n",
      "training-eval,[0.02564985305070877, 0.9955223798751831]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,324,1,4,331\n",
      "validation-eval,[0.025812262669205666, 0.9939393997192383]\n",
      "processing 3.benign.csv rows = 1000\n",
      "processing 3.gafgyt.combo.csv rows = 100\n",
      "processing 3.gafgyt.junk.csv rows = 100\n",
      "processing 3.gafgyt.scan.csv rows = 100\n",
      "processing 3.gafgyt.tcp.csv rows = 100\n",
      "processing 3.gafgyt.udp.csv rows = 100\n",
      "========Ennio_Doorbell========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [7.0, 5.0, 4.0, 3.0, 3.0]\n",
      "complexity:  450.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,338,0,1,666\n",
      "training-eval,[0.008179922588169575, 0.9990049600601196]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,162,0,4,329\n",
      "validation-eval,[0.07884014397859573, 0.991919219493866]\n",
      "processing 4.benign.csv rows = 1000\n",
      "processing 4.gafgyt.combo.csv rows = 100\n",
      "processing 4.gafgyt.junk.csv rows = 100\n",
      "processing 4.gafgyt.scan.csv rows = 100\n",
      "processing 4.gafgyt.tcp.csv rows = 100\n",
      "processing 4.gafgyt.udp.csv rows = 100\n",
      "processing 4.mirai.ack.csv rows = 100\n",
      "processing 4.mirai.scan.csv rows = 100\n",
      "processing 4.mirai.syn.csv rows = 100\n",
      "processing 4.mirai.udp.csv rows = 100\n",
      "processing 4.mirai.udpplain.csv rows = 100\n",
      "========Philips_B120N10_Baby_Monitor========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [8.0, 6.0, 5.0, 4.0]\n",
      "complexity:  526.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,658,1,5,676\n",
      "training-eval,[0.014636756852269173, 0.996268630027771]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,340,1,5,314\n",
      "validation-eval,[0.02895757555961609, 0.9909090995788574]\n",
      "processing 5.benign.csv rows = 1000\n",
      "processing 5.gafgyt.combo.csv rows = 100\n",
      "processing 5.gafgyt.junk.csv rows = 100\n",
      "processing 5.gafgyt.scan.csv rows = 100\n",
      "processing 5.gafgyt.tcp.csv rows = 100\n",
      "processing 5.gafgyt.udp.csv rows = 100\n",
      "processing 5.mirai.ack.csv rows = 100\n",
      "processing 5.mirai.scan.csv rows = 100\n",
      "processing 5.mirai.syn.csv rows = 100\n",
      "processing 5.mirai.udp.csv rows = 100\n",
      "processing 5.mirai.udpplain.csv rows = 100\n",
      "========Provision_PT_737E_Security_Camera========\n",
      "Features=36\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  281.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.98,660,20,6,654\n",
      "training-eval,[0.037463996559381485, 0.9820895791053772]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.97,309,11,10,330\n",
      "validation-eval,[0.0862792357802391, 0.9621211886405945]\n",
      "processing 6.benign.csv rows = 1000\n",
      "processing 6.gafgyt.combo.csv rows = 100\n",
      "processing 6.gafgyt.junk.csv rows = 100\n",
      "processing 6.gafgyt.scan.csv rows = 100\n",
      "processing 6.gafgyt.tcp.csv rows = 100\n",
      "processing 6.gafgyt.udp.csv rows = 100\n",
      "processing 6.mirai.ack.csv rows = 100\n",
      "processing 6.mirai.scan.csv rows = 100\n",
      "processing 6.mirai.syn.csv rows = 100\n",
      "processing 6.mirai.udp.csv rows = 100\n",
      "processing 6.mirai.udpplain.csv rows = 100\n",
      "========Provision_PT_838_Security_Camera========\n",
      "Features=41\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  311.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,665,0,6,669\n",
      "training-eval,[0.016338519752025604, 0.9955223798751831]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.98,334,1,10,315\n",
      "validation-eval,[0.12569990754127502, 0.9848484992980957]\n",
      "processing 7.benign.csv rows = 1000\n",
      "processing 7.gafgyt.combo.csv rows = 100\n",
      "processing 7.gafgyt.junk.csv rows = 100\n",
      "processing 7.gafgyt.scan.csv rows = 100\n",
      "processing 7.gafgyt.tcp.csv rows = 100\n",
      "processing 7.gafgyt.udp.csv rows = 100\n",
      "========Samsung_SNH_1011_N_Webcam========\n",
      "Features=47\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [7.0, 5.0, 4.0, 3.0, 3.0]\n",
      "complexity:  408.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,318,0,2,685\n",
      "training-eval,[0.009889023378491402, 0.998009979724884]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,1.00,181,1,1,312\n",
      "validation-eval,[0.023715173825621605, 0.9959595799446106]\n",
      "processing 8.benign.csv rows = 1000\n",
      "processing 8.gafgyt.combo.csv rows = 100\n",
      "processing 8.gafgyt.junk.csv rows = 100\n",
      "processing 8.gafgyt.scan.csv rows = 100\n",
      "processing 8.gafgyt.tcp.csv rows = 100\n",
      "processing 8.gafgyt.udp.csv rows = 100\n",
      "processing 8.mirai.ack.csv rows = 100\n",
      "processing 8.mirai.scan.csv rows = 100\n",
      "processing 8.mirai.syn.csv rows = 100\n",
      "processing 8.mirai.udp.csv rows = 100\n",
      "processing 8.mirai.udpplain.csv rows = 100\n",
      "========SimpleHome_XCS7_1002_WHT_Security_Camera========\n",
      "Features=51\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  371.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.99,662,6,8,664\n",
      "training-eval,[0.01935494691133499, 0.9902985095977783]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,325,7,2,326\n",
      "validation-eval,[0.050733327865600586, 0.989393949508667]\n",
      "processing 9.benign.csv rows = 1000\n",
      "processing 9.gafgyt.combo.csv rows = 100\n",
      "processing 9.gafgyt.junk.csv rows = 100\n",
      "processing 9.gafgyt.scan.csv rows = 100\n",
      "processing 9.gafgyt.tcp.csv rows = 100\n",
      "processing 9.gafgyt.udp.csv rows = 100\n",
      "processing 9.mirai.ack.csv rows = 100\n",
      "processing 9.mirai.scan.csv rows = 100\n",
      "processing 9.mirai.syn.csv rows = 100\n",
      "processing 9.mirai.udp.csv rows = 100\n",
      "processing 9.mirai.udpplain.csv rows = 100\n",
      "========SimpleHome_XCS7_1003_WHT_Security_Camera========\n",
      "Features=44\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 6.0, 5.0, 4.0, 3.0]\n",
      "complexity:  465.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,683,0,1,656\n",
      "training-eval,[0.004647007677704096, 0.9992537498474121]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,315,2,4,339\n",
      "validation-eval,[0.07713602483272552, 0.9909090995788574]\n"
     ]
    }
   ],
   "source": [
    "device_to = 9 if not debug_flag else 9\n",
    "for i in range(device_to):\n",
    "    device_index = i\n",
    "    device_id = device_index + 1\n",
    "    device_name = dn_nbaiot[device_index]\n",
    "    if not debug_flag:\n",
    "        (X, y, Xdf) = get_nbaiot_device_data(device_id)\n",
    "    else:\n",
    "        (X, y, Xdf) = get_nbaiot_device_data(device_id, 1000, 100)\n",
    "    X = remove_correlated_features(Xdf, 0.98)\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    indices_norm = np.where(y >= 0.5)\n",
    "    indices_anom = np.where(y <= 0.5)\n",
    "    X_norm_all = X_std[indices_norm]\n",
    "    X_anom_all = X_std[indices_anom]\n",
    "    X_std = select_features(X_std, X_norm_all, X_anom_all,75)\n",
    "    evaluate_different_structures(device_name, X_std, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T02:47:58.401099Z",
     "iopub.status.busy": "2020-10-06T02:47:58.399971Z",
     "iopub.status.idle": "2020-10-06T02:47:58.404120Z",
     "shell.execute_reply": "2020-10-06T02:47:58.404735Z"
    },
    "papermill": {
     "duration": 0.083194,
     "end_time": "2020-10-06T02:47:58.404890",
     "exception": false,
     "start_time": "2020-10-06T02:47:58.321696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 0\\ndevice_index = i\\ndevice_id = device_index + 1\\ndevice_name = dn_nbaiot[device_index]\\nif not debug_flag:\\n    (X, y, Xdf) = get_nbaiot_device_data(device_id)\\nelse:\\n    (X, y, Xdf) = get_nbaiot_device_data(device_id, 1000, 100)\\nX = remove_correlated_features(Xdf, 0.98)\\nX_std = StandardScaler().fit_transform(X)\\nindices_norm = np.where(y >= 0.5)\\nindices_anom = np.where(y <= 0.5)\\nX_norm_all = X_std[indices_norm]\\nX_anom_all = X_std[indices_anom]\\nX_std = select_features(X_std, X_norm_all, X_anom_all,75)\\nevaluate_different_structures(device_name, X_std, y)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run test for individual device\n",
    "'''\n",
    "i = 0\n",
    "device_index = i\n",
    "device_id = device_index + 1\n",
    "device_name = dn_nbaiot[device_index]\n",
    "if not debug_flag:\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id)\n",
    "else:\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id, 1000, 100)\n",
    "X = remove_correlated_features(Xdf, 0.98)\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "indices_norm = np.where(y >= 0.5)\n",
    "indices_anom = np.where(y <= 0.5)\n",
    "X_norm_all = X_std[indices_norm]\n",
    "X_anom_all = X_std[indices_anom]\n",
    "X_std = select_features(X_std, X_norm_all, X_anom_all,75)\n",
    "evaluate_different_structures(device_name, X_std, y)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 338.568517,
   "end_time": "2020-10-06T02:47:58.568006",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-06T02:42:19.999489",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
