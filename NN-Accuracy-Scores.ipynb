{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:24.889102Z",
     "iopub.status.busy": "2020-11-01T08:57:24.888301Z",
     "iopub.status.idle": "2020-11-01T08:57:31.039678Z",
     "shell.execute_reply": "2020-11-01T08:57:31.038852Z"
    },
    "papermill": {
     "duration": 6.182292,
     "end_time": "2020-11-01T08:57:31.039807",
     "exception": false,
     "start_time": "2020-11-01T08:57:24.857515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "########################################################################\n",
    "# Python Standard Libraries\n",
    "import os\n",
    "import multiprocessing\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "import math\n",
    "\n",
    "########################################################################\n",
    "# Numpy Library\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "########################################################################\n",
    "# Pandas Library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "########################################################################\n",
    "# MATPLOT Library\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "########################################################################\n",
    "# SKLearn Library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, classification_report, confusion_matrix, average_precision_score, roc_curve, auc, multilabel_confusion_matrix\n",
    "\n",
    "########################################################################\n",
    "# SCIPY Library\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Keras Library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "########################################################################\n",
    "# Init random seed\n",
    "#seed = 13\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:31.089866Z",
     "iopub.status.busy": "2020-11-01T08:57:31.084716Z",
     "iopub.status.idle": "2020-11-01T08:57:31.860007Z",
     "shell.execute_reply": "2020-11-01T08:57:31.859376Z"
    },
    "papermill": {
     "duration": 0.809527,
     "end_time": "2020-11-01T08:57:31.860139",
     "exception": false,
     "start_time": "2020-11-01T08:57:31.050612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM:                   18.571419 GB\n",
      "CORES:                 4\n",
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              4\r\n",
      "On-line CPU(s) list: 0-3\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  2\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               79\r\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
      "Stepping:            0\r\n",
      "CPU MHz:             2200.000\r\n",
      "BogoMIPS:            4400.00\r\n",
      "Hypervisor vendor:   KVM\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            56320K\r\n",
      "NUMA node0 CPU(s):   0-3\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "########################################################################\n",
    "# Print system information\n",
    "def print_system_info():\n",
    "    mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "    mem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\n",
    "    print(\"{:<23}{:f} GB\".format('RAM:', mem_gib))\n",
    "    print(\"{:<23}{:d}\".format('CORES:', multiprocessing.cpu_count()))\n",
    "    !lscpu\n",
    "\n",
    "########################################################################\n",
    "# Walk through input files\n",
    "def print_input_files():\n",
    "    # Input data files are available in the \"../input/\" directory.\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "########################################################################\n",
    "# Dump text files\n",
    "def dump_text_file(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "########################################################################\n",
    "# Dump CSV files\n",
    "def dump_csv_file(fname, count=5):\n",
    "    # count: 0 - column names only, -1 - all rows, default = 5 rows max\n",
    "    df = pd.read_csv(fname)\n",
    "    if count < 0:\n",
    "        count = df.shape[0]\n",
    "    return df.head(count)\n",
    "\n",
    "########################################################################\n",
    "# Dataset related functions\n",
    "ds_nbaiot = '/kaggle/input/nbaiot-dataset'\n",
    "dn_nbaiot = ['Danmini_Doorbell', 'Ecobee_Thermostat', 'Ennio_Doorbell', 'Philips_B120N10_Baby_Monitor', 'Provision_PT_737E_Security_Camera', 'Provision_PT_838_Security_Camera', 'Samsung_SNH_1011_N_Webcam', 'SimpleHome_XCS7_1002_WHT_Security_Camera', 'SimpleHome_XCS7_1003_WHT_Security_Camera']\n",
    "\n",
    "def fname(ds, f):\n",
    "    if '.csv' not in f:\n",
    "        f = f'{f}.csv'\n",
    "    return os.path.join(ds, f)\n",
    "\n",
    "def fname_nbaiot(f):\n",
    "    return fname(ds_nbaiot, f)\n",
    "\n",
    "def get_nbaiot_device_files():\n",
    "    nbaiot_all_files = dump_csv_file(fname_nbaiot('data_summary'), -1)\n",
    "    nbaiot_all_files = nbaiot_all_files.iloc[:,0:1].values\n",
    "    device_id = 1\n",
    "    indices = []\n",
    "    for j in range(len(nbaiot_all_files)):\n",
    "        if str(device_id) not in str(nbaiot_all_files[j]):\n",
    "            indices.append(j)\n",
    "            device_id += 1\n",
    "    nbaiot_device_files = np.split(nbaiot_all_files, indices)\n",
    "    return nbaiot_device_files\n",
    "\n",
    "def get_nbaiot_device_data(device_id, count_norm=-1, count_anom=-1):\n",
    "    if device_id < 1 or device_id > 9:\n",
    "        assert False, \"Please provide a valid device ID 1-9, both inclusive\"\n",
    "    if count_anom == -1:\n",
    "        count_anom = count_norm\n",
    "    device_index = device_id -1\n",
    "    device_files = get_nbaiot_device_files()\n",
    "    device_file = device_files[device_index]\n",
    "    df = pd.DataFrame()\n",
    "    y = []\n",
    "    for i in range(len(device_file)):\n",
    "        fname = str(device_file[i][0])\n",
    "        df_c = pd.read_csv(fname_nbaiot(fname))\n",
    "        count = count_anom\n",
    "        if 'benign' in fname:\n",
    "            count = count_norm\n",
    "        count = min(count, df_c.shape[0]) if count >=0 else df_c.shape[0]\n",
    "        rows = count\n",
    "        print(\"processing\", fname, \"rows =\", rows)\n",
    "        y_np = np.ones(rows) if 'benign' in fname else np.zeros(rows)\n",
    "        y.extend(y_np.tolist())\n",
    "        df = pd.concat([df.iloc[:,:].reset_index(drop=True),\n",
    "                      df_c.iloc[:rows,:].reset_index(drop=True)], axis=0)\n",
    "    X = df.iloc[:,:].values\n",
    "    y = np.array(y)\n",
    "    Xdf = df\n",
    "    return (X, y, Xdf)\n",
    "\n",
    "def get_nbaiot_devices_data():\n",
    "    devices_data = []\n",
    "    for i in range(9):\n",
    "        device_id = i + 1\n",
    "        (X, y) = get_nbaiot_device_data(device_id)\n",
    "        devices_data.append((X, y))\n",
    "    return devices_data\n",
    "#print_input_files()\n",
    "print_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:31.901196Z",
     "iopub.status.busy": "2020-11-01T08:57:31.900416Z",
     "iopub.status.idle": "2020-11-01T08:57:31.903194Z",
     "shell.execute_reply": "2020-11-01T08:57:31.902615Z"
    },
    "papermill": {
     "duration": 0.031546,
     "end_time": "2020-11-01T08:57:31.903307",
     "exception": false,
     "start_time": "2020-11-01T08:57:31.871761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold):\n",
    "    df = df.copy()\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find features with correlation greater than a threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    # Drop features \n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "    return df.iloc[:,:].values\n",
    "\n",
    "def mark_important_features(vector, pc_keep): # pc_keep is the percentage (0-100) of labels to keep\n",
    "    th = np.percentile(vector,(100-pc_keep)) # threshold, calculate percentile (100 - percentage) from percentage\n",
    "    important_bool = (vector >= th)\n",
    "    important_int = important_bool.astype(int)\n",
    "    return important_int\n",
    "\n",
    "def select_features(X, X_norm, X_anom, threshold):\n",
    "    rows_n = X_norm.shape[0]\n",
    "    rows_a = X_anom.shape[0]\n",
    "    if rows_n == 0 or rows_a == 0:\n",
    "        return X\n",
    "\n",
    "    y_norm = np.ones(rows_n)\n",
    "    y_anom = -1 * np.ones(rows_a)\n",
    "\n",
    "    reg_n = LinearRegression(fit_intercept=False)\n",
    "    reg_n.fit(X_norm, y_norm)\n",
    "    coef_n = abs(reg_n.coef_)\n",
    "    n = mark_important_features(coef_n, threshold)\n",
    "\n",
    "    reg_a = LinearRegression(fit_intercept=False)\n",
    "    reg_a.fit(X_anom, y_anom)\n",
    "    coef_a = abs(reg_a.coef_)\n",
    "    a = mark_important_features(coef_a, threshold)\n",
    "   \n",
    "    mask = np.bitwise_or(n,a)\n",
    "    mask = mask == 1 # convert to Boolean\n",
    "    X_sel = X[:, mask]\n",
    "    return X_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:31.935199Z",
     "iopub.status.busy": "2020-11-01T08:57:31.934200Z",
     "iopub.status.idle": "2020-11-01T08:57:31.937470Z",
     "shell.execute_reply": "2020-11-01T08:57:31.936924Z"
    },
    "papermill": {
     "duration": 0.023042,
     "end_time": "2020-11-01T08:57:31.937606",
     "exception": false,
     "start_time": "2020-11-01T08:57:31.914564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def place_optimal(a):\n",
    "    if len(a) == 0:\n",
    "        return []\n",
    "    if len(a) == 1:\n",
    "        return [a[0]]\n",
    "    if len(a) == 2:\n",
    "        return [a[-1], a[0]]\n",
    "\n",
    "    x = [a[-1], a[0]]\n",
    "    y = place_optimal(a[1:-1])\n",
    "    y.reverse()\n",
    "    x.extend(y)\n",
    "    return x\n",
    "\n",
    "def place_layers(a):\n",
    "    a.sort()\n",
    "    return place_optimal(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:31.973704Z",
     "iopub.status.busy": "2020-11-01T08:57:31.968433Z",
     "iopub.status.idle": "2020-11-01T08:57:31.990217Z",
     "shell.execute_reply": "2020-11-01T08:57:31.989622Z"
    },
    "papermill": {
     "duration": 0.041356,
     "end_time": "2020-11-01T08:57:31.990331",
     "exception": false,
     "start_time": "2020-11-01T08:57:31.948975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_changes(x, y):\n",
    "    assert x.ndim == 1 and y.ndim == 1, 'Expecting 1 dimension array, received x: {} and y: {}'.format(x.ndim, y.ndim)\n",
    "    x = x.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    xy = np.column_stack((x,y))\n",
    "    xy = xy[np.argsort(xy[:, 0])] # sort by x\n",
    "    changes = 0\n",
    "    prev_y = None\n",
    "    for i in range(1, xy.shape[0]):\n",
    "        y = xy[i][1]\n",
    "        if y != prev_y:\n",
    "            prev_y = y\n",
    "            changes += 1\n",
    "    return changes\n",
    "\n",
    "def create_network_structure_dahlia(X, y):\n",
    "    changes = []\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i]\n",
    "        change = compute_changes(x,y)\n",
    "        changes.append(change)\n",
    "    structure = list(set(changes))\n",
    "    structure = list(set(np.ceil(np.log(structure))))\n",
    "    N = X.shape[0]\n",
    "    structure = [np.floor(math.sqrt(N/2)/s) for s in structure]\n",
    "    structure = place_layers(structure)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_heuristics(X, y):\n",
    "    structure = []\n",
    "    N = X.shape[0]\n",
    "    m = 1\n",
    "    node_count_layer_1 = int(math.sqrt((m + 2) * N) + 2 * math.sqrt(N / (m + 2)))\n",
    "    node_count_layer_2 = int(m * math.sqrt(N / (m + 2)))\n",
    "    structure.append(node_count_layer_1)\n",
    "    structure.append(node_count_layer_2)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_genetic(X, y):\n",
    "    structure = []\n",
    "    l = 18\n",
    "    K = 11\n",
    "    chromosome = ''\n",
    "    for i in range(l):\n",
    "        x = random.randint(0, 1)\n",
    "        chromosome += '{}'.format(x)\n",
    "    chromosome_left = chromosome[0:K]\n",
    "    chromosome_right = chromosome[K:]\n",
    "    #print('chromosome: {}'.format(chromosome))\n",
    "    #print('split: {} {}'.format(chromosome_left, chromosome_right))\n",
    "    #print('chromosome_left: {}'.format(chromosome_left))\n",
    "    #print('chromosome_right: {}'.format(chromosome_right))\n",
    "    node_count_layer_1 = int(chromosome_left, 2) + random.randint(1, 10)\n",
    "    node_count_layer_2 = int(chromosome_right, 2) + random.randint(1, 10)\n",
    "    structure.append(node_count_layer_1)\n",
    "    structure.append(node_count_layer_2)\n",
    "    return structure\n",
    "\n",
    "def create_network_structure_random(X, y):\n",
    "    layer_count_min = 15\n",
    "    layer_count_max = 25\n",
    "    node_count_min = 10\n",
    "    node_count_max = 97\n",
    "    \n",
    "    structure = []\n",
    "    layer_count = random.randint(layer_count_min, layer_count_max)\n",
    "    for i in range(layer_count):\n",
    "        node_count = random.randint(node_count_min, node_count_max)\n",
    "        structure.append(node_count)\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:32.024019Z",
     "iopub.status.busy": "2020-11-01T08:57:32.023156Z",
     "iopub.status.idle": "2020-11-01T08:57:32.026102Z",
     "shell.execute_reply": "2020-11-01T08:57:32.025551Z"
    },
    "papermill": {
     "duration": 0.0242,
     "end_time": "2020-11-01T08:57:32.026217",
     "exception": false,
     "start_time": "2020-11-01T08:57:32.002017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_binary_classifier(hidden_layers, input_dim):\n",
    "    layers = []\n",
    "    for hl in hidden_layers:\n",
    "        if hl > 0:\n",
    "            layers.append(hl)\n",
    "\n",
    "    layer_count = len(layers)\n",
    "    assert layer_count >= 1, 'at least 1 non-zero hidden layer is needed'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0],input_dim=input_dim,activation='relu'))\n",
    "    for i in range(1, layer_count):\n",
    "        model.add(Dense(layers[i],activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #model.summary()\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer ='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:32.056906Z",
     "iopub.status.busy": "2020-11-01T08:57:32.055961Z",
     "iopub.status.idle": "2020-11-01T08:57:32.059273Z",
     "shell.execute_reply": "2020-11-01T08:57:32.058597Z"
    },
    "papermill": {
     "duration": 0.021371,
     "end_time": "2020-11-01T08:57:32.059381",
     "exception": false,
     "start_time": "2020-11-01T08:57:32.038010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_time_complexity_single_pass(neurons_input, structure, neurons_output):\n",
    "    count_hidden_layers = len(structure)\n",
    "    neurons = [neurons_input, *structure, neurons_output]\n",
    "    complexity = 0\n",
    "    for i in range(count_hidden_layers + 1):\n",
    "        complexity += neurons[i] * neurons[i+1]\n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:32.098600Z",
     "iopub.status.busy": "2020-11-01T08:57:32.096480Z",
     "iopub.status.idle": "2020-11-01T08:57:32.102146Z",
     "shell.execute_reply": "2020-11-01T08:57:32.101556Z"
    },
    "papermill": {
     "duration": 0.030978,
     "end_time": "2020-11-01T08:57:32.102258",
     "exception": false,
     "start_time": "2020-11-01T08:57:32.071280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_report(title, model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = (y_pred > 0.25)\n",
    "    #print(y_pred)\n",
    "    #y_pred[y_pred <= 0] = -1 # convert negative values as 0 for anomaly\n",
    "    #y_pred[y_pred > 0] = 1 # convert positive values as 1 for normal\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"title,acc,tn,fp,fn,tp\")\n",
    "    print(f'{title}-cm,{acc:.2f},{tn},{fp},{fn},{tp}')\n",
    "    #print(f'{cr}')\n",
    "    results = model.evaluate(X, y, verbose=0)\n",
    "    print(f'{title}-eval,{results}')\n",
    "\n",
    "def evaluate_different_structures(title, X, y):\n",
    "    #y[y <= 0] = -1 # map negative and 0 as anomaly (-1)\n",
    "    #y[y > 0] = 1 # map positive numbers as normal (1)\n",
    "    algorithms = [\n",
    "        {'name': 'Dahlia', 'fx': create_network_structure_dahlia},\n",
    "        #{'name': 'Heuristics', 'fx': create_network_structure_heuristics},\n",
    "        #{'name': 'Genetic', 'fx': create_network_structure_genetic},\n",
    "        #{'name': 'Random', 'fx': create_network_structure_random},\n",
    "    ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    print (f\"========{title}========\")\n",
    "    feature_count = X.shape[1]\n",
    "    print(f'Features={feature_count}')\n",
    "    for algo in algorithms:\n",
    "        print(f\"********{algo['name']}********\")\n",
    "        structure = algo['fx'](X_train,y_train)\n",
    "        print(f'NN Structure: layers={len(structure)}, neurons: {structure}')\n",
    "        print('complexity: ', compute_time_complexity_single_pass(feature_count, structure, 1))\n",
    "        model = create_binary_classifier(structure, feature_count)\n",
    "        model.fit(X_train,y_train,epochs=150,batch_size=10,verbose=0)\n",
    "        compute_report('training', model, X_train, y_train)\n",
    "        compute_report('validation', model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:32.131330Z",
     "iopub.status.busy": "2020-11-01T08:57:32.130329Z",
     "iopub.status.idle": "2020-11-01T08:57:32.133523Z",
     "shell.execute_reply": "2020-11-01T08:57:32.132848Z"
    },
    "papermill": {
     "duration": 0.019384,
     "end_time": "2020-11-01T08:57:32.133655",
     "exception": false,
     "start_time": "2020-11-01T08:57:32.114271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T08:57:32.173968Z",
     "iopub.status.busy": "2020-11-01T08:57:32.173210Z",
     "iopub.status.idle": "2020-11-01T09:02:55.566597Z",
     "shell.execute_reply": "2020-11-01T09:02:55.565980Z"
    },
    "papermill": {
     "duration": 323.419406,
     "end_time": "2020-11-01T09:02:55.566735",
     "exception": false,
     "start_time": "2020-11-01T08:57:32.147329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1.benign.csv rows = 1000\n",
      "processing 1.gafgyt.combo.csv rows = 100\n",
      "processing 1.gafgyt.junk.csv rows = 100\n",
      "processing 1.gafgyt.scan.csv rows = 100\n",
      "processing 1.gafgyt.tcp.csv rows = 100\n",
      "processing 1.gafgyt.udp.csv rows = 100\n",
      "processing 1.mirai.ack.csv rows = 100\n",
      "processing 1.mirai.scan.csv rows = 100\n",
      "processing 1.mirai.syn.csv rows = 100\n",
      "processing 1.mirai.udp.csv rows = 100\n",
      "processing 1.mirai.udpplain.csv rows = 100\n",
      "========Danmini_Doorbell========\n",
      "Features=43\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 3.0, 5.0, 4.0, 6.0]\n",
      "complexity:  433.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.99,669,8,1,662\n",
      "training-eval,[0.017414389178156853, 0.9940298795700073]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,320,3,4,333\n",
      "validation-eval,[0.0544172003865242, 0.9909090995788574]\n",
      "processing 2.benign.csv rows = 1000\n",
      "processing 2.gafgyt.combo.csv rows = 100\n",
      "processing 2.gafgyt.junk.csv rows = 100\n",
      "processing 2.gafgyt.scan.csv rows = 100\n",
      "processing 2.gafgyt.tcp.csv rows = 100\n",
      "processing 2.gafgyt.udp.csv rows = 100\n",
      "processing 2.mirai.ack.csv rows = 100\n",
      "processing 2.mirai.scan.csv rows = 100\n",
      "processing 2.mirai.syn.csv rows = 100\n",
      "processing 2.mirai.udp.csv rows = 100\n",
      "processing 2.mirai.udpplain.csv rows = 100\n",
      "========Ecobee_Thermostat========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 3.0, 5.0, 4.0, 6.0]\n",
      "complexity:  513.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,668,0,3,669\n",
      "training-eval,[0.010399010963737965, 0.9977611899375916]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,332,0,7,321\n",
      "validation-eval,[0.04237907752394676, 0.989393949508667]\n",
      "processing 3.benign.csv rows = 1000\n",
      "processing 3.gafgyt.combo.csv rows = 100\n",
      "processing 3.gafgyt.junk.csv rows = 100\n",
      "processing 3.gafgyt.scan.csv rows = 100\n",
      "processing 3.gafgyt.tcp.csv rows = 100\n",
      "processing 3.gafgyt.udp.csv rows = 100\n",
      "========Ennio_Doorbell========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [7.0, 3.0, 4.0, 3.0, 5.0]\n",
      "complexity:  436.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,339,0,1,665\n",
      "training-eval,[0.007036538328975439, 0.9990049600601196]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,1.00,160,1,1,333\n",
      "validation-eval,[0.014560478739440441, 0.9959595799446106]\n",
      "processing 4.benign.csv rows = 1000\n",
      "processing 4.gafgyt.combo.csv rows = 100\n",
      "processing 4.gafgyt.junk.csv rows = 100\n",
      "processing 4.gafgyt.scan.csv rows = 100\n",
      "processing 4.gafgyt.tcp.csv rows = 100\n",
      "processing 4.gafgyt.udp.csv rows = 100\n",
      "processing 4.mirai.ack.csv rows = 100\n",
      "processing 4.mirai.scan.csv rows = 100\n",
      "processing 4.mirai.syn.csv rows = 100\n",
      "processing 4.mirai.udp.csv rows = 100\n",
      "processing 4.mirai.udpplain.csv rows = 100\n",
      "========Philips_B120N10_Baby_Monitor========\n",
      "Features=53\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [8.0, 4.0, 5.0, 6.0]\n",
      "complexity:  512.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.99,680,3,5,652\n",
      "training-eval,[0.01946537010371685, 0.9947761297225952]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.99,315,2,3,340\n",
      "validation-eval,[0.017461607232689857, 0.9924242496490479]\n",
      "processing 5.benign.csv rows = 1000\n",
      "processing 5.gafgyt.combo.csv rows = 100\n",
      "processing 5.gafgyt.junk.csv rows = 100\n",
      "processing 5.gafgyt.scan.csv rows = 100\n",
      "processing 5.gafgyt.tcp.csv rows = 100\n",
      "processing 5.gafgyt.udp.csv rows = 100\n",
      "processing 5.mirai.ack.csv rows = 100\n",
      "processing 5.mirai.scan.csv rows = 100\n",
      "processing 5.mirai.syn.csv rows = 100\n",
      "processing 5.mirai.udp.csv rows = 100\n",
      "processing 5.mirai.udpplain.csv rows = 100\n",
      "========Provision_PT_737E_Security_Camera========\n",
      "Features=36\n",
      "********Dahlia********\n",
      "NN Structure: layers=3, neurons: [5.0, 3.0, 4.0]\n",
      "complexity:  211.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.99,651,3,8,678\n",
      "training-eval,[0.028923939913511276, 0.9932835698127747]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.98,342,4,9,305\n",
      "validation-eval,[0.16994445025920868, 0.9848484992980957]\n",
      "processing 6.benign.csv rows = 1000\n",
      "processing 6.gafgyt.combo.csv rows = 100\n",
      "processing 6.gafgyt.junk.csv rows = 100\n",
      "processing 6.gafgyt.scan.csv rows = 100\n",
      "processing 6.gafgyt.tcp.csv rows = 100\n",
      "processing 6.gafgyt.udp.csv rows = 100\n",
      "processing 6.mirai.ack.csv rows = 100\n",
      "processing 6.mirai.scan.csv rows = 100\n",
      "processing 6.mirai.syn.csv rows = 100\n",
      "processing 6.mirai.udp.csv rows = 100\n",
      "processing 6.mirai.udpplain.csv rows = 100\n",
      "========Provision_PT_838_Security_Camera========\n",
      "Features=41\n",
      "********Dahlia********\n",
      "NN Structure: layers=4, neurons: [6.0, 3.0, 4.0, 5.0]\n",
      "complexity:  301.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,0.98,658,21,5,656\n",
      "training-eval,[0.036053333431482315, 0.987313449382782]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.97,305,16,2,337\n",
      "validation-eval,[0.11863194406032562, 0.9863636493682861]\n",
      "processing 7.benign.csv rows = 1000\n",
      "processing 7.gafgyt.combo.csv rows = 100\n",
      "processing 7.gafgyt.junk.csv rows = 100\n",
      "processing 7.gafgyt.scan.csv rows = 100\n",
      "processing 7.gafgyt.tcp.csv rows = 100\n",
      "processing 7.gafgyt.udp.csv rows = 100\n",
      "========Samsung_SNH_1011_N_Webcam========\n",
      "Features=47\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [7.0, 3.0, 4.0, 3.0, 5.0]\n",
      "complexity:  394.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,339,0,3,663\n",
      "training-eval,[0.017158208414912224, 0.9970149397850037]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,1.00,160,1,1,333\n",
      "validation-eval,[0.02474357932806015, 0.9959595799446106]\n",
      "processing 8.benign.csv rows = 1000\n",
      "processing 8.gafgyt.combo.csv rows = 100\n",
      "processing 8.gafgyt.junk.csv rows = 100\n",
      "processing 8.gafgyt.scan.csv rows = 100\n",
      "processing 8.gafgyt.tcp.csv rows = 100\n",
      "processing 8.gafgyt.udp.csv rows = 100\n",
      "processing 8.mirai.ack.csv rows = 100\n",
      "processing 8.mirai.scan.csv rows = 100\n",
      "processing 8.mirai.syn.csv rows = 100\n",
      "processing 8.mirai.udp.csv rows = 100\n",
      "processing 8.mirai.udpplain.csv rows = 100\n",
      "========SimpleHome_XCS7_1002_WHT_Security_Camera========\n",
      "Features=51\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 3.0, 5.0, 4.0, 6.0]\n",
      "complexity:  497.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,681,2,3,654\n",
      "training-eval,[0.012048998847603798, 0.9970149397850037]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,0.98,313,4,10,333\n",
      "validation-eval,[0.077353335916996, 0.9833333492279053]\n",
      "processing 9.benign.csv rows = 1000\n",
      "processing 9.gafgyt.combo.csv rows = 100\n",
      "processing 9.gafgyt.junk.csv rows = 100\n",
      "processing 9.gafgyt.scan.csv rows = 100\n",
      "processing 9.gafgyt.tcp.csv rows = 100\n",
      "processing 9.gafgyt.udp.csv rows = 100\n",
      "processing 9.mirai.ack.csv rows = 100\n",
      "processing 9.mirai.scan.csv rows = 100\n",
      "processing 9.mirai.syn.csv rows = 100\n",
      "processing 9.mirai.udp.csv rows = 100\n",
      "processing 9.mirai.udpplain.csv rows = 100\n",
      "========SimpleHome_XCS7_1003_WHT_Security_Camera========\n",
      "Features=44\n",
      "********Dahlia********\n",
      "NN Structure: layers=5, neurons: [8.0, 3.0, 5.0, 4.0, 6.0]\n",
      "complexity:  441.0\n",
      "title,acc,tn,fp,fn,tp\n",
      "training-cm,1.00,660,0,2,678\n",
      "training-eval,[0.008512372151017189, 0.9985074400901794]\n",
      "title,acc,tn,fp,fn,tp\n",
      "validation-cm,1.00,340,0,2,318\n",
      "validation-eval,[0.017288584262132645, 0.9969696998596191]\n"
     ]
    }
   ],
   "source": [
    "if debug_flag:\n",
    "    count_norm = 1000\n",
    "    count_anom = 100\n",
    "    #device_indices = [0]\n",
    "    device_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "else:\n",
    "    count_norm = -1\n",
    "    count_anom = -1\n",
    "    device_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    \n",
    "for i in device_indices:\n",
    "    device_index = i\n",
    "    device_id = device_index + 1\n",
    "    device_name = dn_nbaiot[device_index]\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id, count_norm, count_anom)\n",
    "    X = remove_correlated_features(Xdf, 0.98)\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    indices_norm = np.where(y >= 0.5)\n",
    "    indices_anom = np.where(y <= 0.5)\n",
    "    X_norm_all = X_std[indices_norm]\n",
    "    X_anom_all = X_std[indices_anom]\n",
    "    X_std = select_features(X_std, X_norm_all, X_anom_all,75)\n",
    "    evaluate_different_structures(device_name, X_std, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T09:02:55.685456Z",
     "iopub.status.busy": "2020-11-01T09:02:55.684517Z",
     "iopub.status.idle": "2020-11-01T09:02:55.688591Z",
     "shell.execute_reply": "2020-11-01T09:02:55.689145Z"
    },
    "papermill": {
     "duration": 0.0674,
     "end_time": "2020-11-01T09:02:55.689286",
     "exception": false,
     "start_time": "2020-11-01T09:02:55.621886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 0\\ndevice_index = i\\ndevice_id = device_index + 1\\ndevice_name = dn_nbaiot[device_index]\\nif not debug_flag:\\n    (X, y, Xdf) = get_nbaiot_device_data(device_id)\\nelse:\\n    (X, y, Xdf) = get_nbaiot_device_data(device_id, 1000, 100)\\nX = remove_correlated_features(Xdf, 0.98)\\nX_std = StandardScaler().fit_transform(X)\\nindices_norm = np.where(y >= 0.5)\\nindices_anom = np.where(y <= 0.5)\\nX_norm_all = X_std[indices_norm]\\nX_anom_all = X_std[indices_anom]\\nX_std = select_features(X_std, X_norm_all, X_anom_all,75)\\nevaluate_different_structures(device_name, X_std, y)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run test for individual device\n",
    "'''\n",
    "i = 0\n",
    "device_index = i\n",
    "device_id = device_index + 1\n",
    "device_name = dn_nbaiot[device_index]\n",
    "if not debug_flag:\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id)\n",
    "else:\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id, 1000, 100)\n",
    "X = remove_correlated_features(Xdf, 0.98)\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "indices_norm = np.where(y >= 0.5)\n",
    "indices_anom = np.where(y <= 0.5)\n",
    "X_norm_all = X_std[indices_norm]\n",
    "X_anom_all = X_std[indices_anom]\n",
    "X_std = select_features(X_std, X_norm_all, X_anom_all,75)\n",
    "evaluate_different_structures(device_name, X_std, y)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 335.4656,
   "end_time": "2020-11-01T09:02:55.854023",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-01T08:57:20.388423",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
